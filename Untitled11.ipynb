{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6Q8UQqrTBNS",
        "outputId": "27738a83-9a47-4568-f507-fb9130a51dc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ”„ Chargement du modÃ¨leâ€¦\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ’» Utilisation du device : cuda\n",
            "ðŸ“„ Lecture robuste du CSVâ€¦\n",
            "âœ” CSV chargÃ© avec 91 colonnes.\n",
            "DÃ©limiteur dÃ©tectÃ© : '|'\n",
            "\n",
            "ðŸš€ Traduction de la colonne : cv_statusâ€¦\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2768/2768 [12:22<00:00,  3.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ” Colonne cv_status traduite â†’ cv_status_fr\n",
            "\n",
            "ðŸš€ Traduction de la colonne : localityNameâ€¦\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2768/2768 [1:24:15<00:00,  1.83s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ” Colonne localityName traduite â†’ localityName_fr\n",
            "\n",
            "ðŸš€ Traduction de la colonne : genderâ€¦\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2768/2768 [07:36<00:00,  6.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ” Colonne gender traduite â†’ gender_fr\n",
            "\n",
            "ðŸš€ Traduction de la colonne : positionNameâ€¦\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|â–ˆâ–ˆâ–ˆâ–      | 959/2768 [31:15<23:39,  1.27it/s]"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import csv\n",
        "import kagglehub\n",
        "\n",
        "# -------------------------\n",
        "# CONFIGURATION\n",
        "# -------------------------\n",
        "\n",
        "DATASET = \"darysha/hse-hackathon\"\n",
        "FILE_PATH = \"train.csv\"   # chemin interne du dataset Kaggle\n",
        "CSV_OUTPUT = \"train_fr.csv\"\n",
        "\n",
        "COLUMNS_TO_TRANSLATE = [\n",
        "    \"cv_status\", \"localityName\", \"gender\", \"positionName\",\n",
        "    \"typicalPosition_cv\", \"skills_cv\", \"otherCertificates\",\n",
        "    \"country\", \"educationList\", \"hardSkills_cv\", \"softSkills_cv\",\n",
        "    \"workExperienceList\", \"scheduleType_cv\", \"retrainingCapability_cv\",\n",
        "    \"businessTrip\", \"languageKnowledge_cv\", \"relocation\", \"innerInfo\",\n",
        "    \"education\", \"vacancyName\", \"professionalSphereName\", \"vacancyAddress\",\n",
        "    \"busyType_vacancy\", \"educationRequirements\", \"hardSkills_vacancy\",\n",
        "    \"softSkills_vacancy\", \"skills_vacancy\", \"typicalPosition_vacancy\",\n",
        "    \"scheduleType_vacancy\", \"otherVacancyBenefit\", \"needMedcard\",\n",
        "    \"sourceType\", \"contactPerson\", \"fullCompanyName\", \"regionName\",\n",
        "    \"positionRequirements\", \"contactList\", \"additionalRequirements\",\n",
        "    \"qualifications\", \"responsibilities\", \"medicalDocument\",\n",
        "    \"benefit\", \"conditions\"\n",
        "]\n",
        "\n",
        "MODEL_NAME = \"Helsinki-NLP/opus-mt-ru-fr\"\n",
        "BATCH_SIZE = 32\n",
        "MAX_LENGTH = 256\n",
        "\n",
        "# -------------------------\n",
        "# LOAD MODEL\n",
        "# -------------------------\n",
        "\n",
        "print(\"ðŸ”„ Chargement du modÃ¨le de traductionâ€¦\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = model.to(device)\n",
        "print(f\"ðŸ’» Device utilisÃ© : {device}\")\n",
        "\n",
        "# -------------------------\n",
        "# DOWNLOAD & LOAD CSV FROM KAGGLE\n",
        "# -------------------------\n",
        "\n",
        "print(\"ðŸ“¥ TÃ©lÃ©chargement du train.csv depuis Kaggleâ€¦\")\n",
        "local_file = kagglehub.dataset_download(DATASET, FILE_PATH)\n",
        "\n",
        "print(\"ðŸ“„ Auto-dÃ©tection du dÃ©limiteurâ€¦\")\n",
        "with open(local_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    sample = f.read(50000)\n",
        "\n",
        "dialect = csv.Sniffer().sniff(sample)\n",
        "print(f\"âœ” DÃ©limiteur dÃ©tectÃ© : '{dialect.delimiter}'\")\n",
        "\n",
        "print(\"ðŸ“„ Lecture robuste du CSVâ€¦\")\n",
        "df = pd.read_csv(\n",
        "    local_file,\n",
        "    sep=dialect.delimiter,\n",
        "    engine=\"python\",\n",
        "    quotechar='\"',\n",
        "    escapechar=\"\\\\\",\n",
        "    on_bad_lines=\"skip\"\n",
        ")\n",
        "\n",
        "print(f\"âœ” CSV chargÃ© : {df.shape[0]} lignes, {df.shape[1]} colonnes.\")\n",
        "\n",
        "# -------------------------\n",
        "# TRANSLATION FUNCTION\n",
        "# -------------------------\n",
        "\n",
        "def translate_batch(batch):\n",
        "    batch = [\"\" if x is None else str(x) for x in batch]\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        batch,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=MAX_LENGTH\n",
        "    ).to(device)\n",
        "\n",
        "    outputs = model.generate(**inputs, max_length=MAX_LENGTH)\n",
        "    return [tokenizer.decode(o, skip_special_tokens=True) for o in outputs]\n",
        "\n",
        "# -------------------------\n",
        "# TRANSLATE COLUMNS\n",
        "# -------------------------\n",
        "\n",
        "for col in COLUMNS_TO_TRANSLATE:\n",
        "    if col not in df.columns:\n",
        "        print(f\"âš ï¸ Colonne absente : {col} â†’ ignorÃ©e\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\nðŸš€ Traduction de la colonne : {col}â€¦\")\n",
        "    texts = df[col].astype(str).fillna(\"\").tolist()\n",
        "    translated = []\n",
        "\n",
        "    for i in tqdm(range(0, len(texts), BATCH_SIZE)):\n",
        "        batch = texts[i:i+BATCH_SIZE]\n",
        "        translated_batch = translate_batch(batch)\n",
        "        translated.extend(translated_batch)\n",
        "\n",
        "    df[col + \"_fr\"] = translated\n",
        "    print(f\"âœ” Colonne {col} traduite â†’ {col}_fr\")\n",
        "\n",
        "# -------------------------\n",
        "# SAVE RESULT\n",
        "# -------------------------\n",
        "\n",
        "df.to_csv(CSV_OUTPUT, index=False, encoding=\"utf-8\")\n",
        "print(f\"\\nðŸŽ‰ Traduction terminÃ©e ! Fichier gÃ©nÃ©rÃ© : {CSV_OUTPUT}\")\n",
        "\n",
        "#le dataset est tÃ©lÃ©chargÃ© et le fichier train.csv est lu\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
